import os
import logging
import traceback
import openai
import httpx
import emoji
from openai import OpenAI
from app.config import Config
from app.models.vector_db import vector_db
import re

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)

conversation_history = []

class QueryRAGSystem:
    def __init__(self):
        logging.info("Inicializando QueryRAGSystem")
        # Configuraci√≥n b√°sica del cliente OpenAI sin proxies
        client = httpx.Client()
        self.client = OpenAI(
            api_key=Config.OPENAI_API_KEY,
            http_client=client
        )
        self.min_similarity_score = 0.55  # Reducido para incluir m√°s consultas de salud
        logging.info(f"API Key configurada: {'Presente' if Config.OPENAI_API_KEY else 'No presente'}")

    def clean_text(self, texto: str) -> str:
        """Limpia y normaliza el texto."""
        # Eliminar emojis
        texto = emoji.replace_emoji(texto, "")
        # Eliminar caracteres especiales pero mantener acentos y √±
        texto = re.sub(r'[^a-z√°√©√≠√≥√∫√±√ºA-Z√Å√â√ç√ì√ö√ë√ú0-9\s.,¬ø?¬°!]', '', texto)
        # Normalizar espacios
        texto = ' '.join(texto.split())
        return texto

    def is_article_list_query(self, query_text):
        """Detecta si la consulta solicita una lista de art√≠culos."""
        query_lower = query_text.lower()
        article_list_patterns = [
            r'qu[e√©]\s+art[i√≠]culos',
            r'cu[a√°]les\s+art[i√≠]culos',
            r'lista\s+de\s+art[i√≠]culos',
            r'todos\s+los\s+art[i√≠]culos',
            r'art[i√≠]culos\s+sobre',
            r'art[i√≠]culos\s+relacionados',
            r'qu[e√©]\s+normas',
            r'cu[a√°]les\s+normas',
            r'dime\s+que\s+art[i√≠]culos',
            r'muestra\s+art[i√≠]culos',
            r'busca\s+art[i√≠]culos'
        ]
        
        for pattern in article_list_patterns:
            if re.search(pattern, query_lower):
                return True
        return False

    def _generate_direct_response(self, results, query_text):
        """Genera una respuesta directa basada en los resultados m√°s relevantes."""
        try:
            if not results:
                return f"No encontr√© informaci√≥n espec√≠fica sobre '{query_text}' en mi base de datos."
            
            # Tomar el resultado m√°s relevante
            best_result = results[0]['data']
            
            # Extraer informaci√≥n relevante
            article_num = best_result.get('articulo', 'N/A')
            source = best_result.get('fuente', 'N/A')
            theme = best_result.get('tema', 'N/A')
            subtheme = best_result.get('subtema', '')
            summary = best_result.get('resumen_explicativo', '')
            full_text = best_result.get('texto_del_articulo', '')
            
            # Construir respuesta directa y clara
            response = f"**{theme}**\n\n"
            
            # A√±adir informaci√≥n del procedimiento/respuesta
            if summary and str(summary).strip() not in ['', 'nan', 'None', 'null']:
                response += f"{summary}\n\n"
            elif full_text and str(full_text).strip() not in ['', 'nan', 'None', 'null']:
                # Si no hay resumen pero s√≠ texto completo, usar un extracto
                extract = full_text[:300] + "..." if len(full_text) > 300 else full_text
                response += f"{extract}\n\n"
            
            # A√±adir referencia al art√≠culo de forma m√°s simple
            response += f"**Referencia:** Art√≠culo {article_num} - {source}"
            if subtheme and str(subtheme).strip() not in ['', 'nan', 'None', 'null']:
                response += f" ({subtheme})"
            response += "\n\n"
            
            # A√±adir informaci√≥n de art√≠culos relacionados si hay m√°s resultados
            if len(results) > 1:
                response += "**Art√≠culos relacionados:**\n"
                for i in range(1, min(4, len(results))):
                    related = results[i]['data']
                    response += f"‚Ä¢ Art. {related.get('articulo', 'N/A')} - {related.get('tema', 'N/A')}"
                    if related.get('subtema') and str(related.get('subtema')).strip() not in ['', 'nan', 'None', 'null']:
                        response += f" ({related.get('subtema')})"
                    response += "\n"
            
            logging.info("Generada respuesta directa estructurada con informaci√≥n legal")
            return response
            
        except Exception as e:
            logging.error(f"Error generando respuesta directa: {e}")
            return f"Encontr√© informaci√≥n sobre '{query_text}', pero hubo un error al procesarla. Por favor, intenta reformular tu pregunta."

    def _validate_article_mentions(self, response_text):
        """Valida que los art√≠culos mencionados en la respuesta existan realmente en la base de datos."""
        import re
        
        # Extraer n√∫meros de art√≠culos mencionados
        article_numbers = re.findall(r'art[√≠i]culo\s*(\d+)', response_text.lower())
        
        if not article_numbers:
            return response_text, True  # No hay art√≠culos que validar
        
        validated_articles = []
        invalid_articles = []
        
        for art_num in set(article_numbers):  # Eliminar duplicados
            try:
                # Verificar si el art√≠culo existe
                article_response, similarity, used_kb = vector_db.get_article_details(art_num)
                
                if "‚ùå **Art√≠culo No Encontrado**" in article_response:
                    invalid_articles.append(art_num)
                    logging.warning(f"Art√≠culo {art_num} mencionado pero no existe en la base de datos")
                else:
                    validated_articles.append(art_num)
                    logging.info(f"Art√≠culo {art_num} validado correctamente")
                    
            except Exception as e:
                logging.error(f"Error validando art√≠culo {art_num}: {e}")
                invalid_articles.append(art_num)
        
        # Si hay art√≠culos inv√°lidos, modificar la respuesta
        if invalid_articles:
            logging.warning(f"Se encontraron art√≠culos inv√°lidos: {invalid_articles}")
            
            # Crear una respuesta m√°s conservadora
            if validated_articles:
                response_text = f"Encontr√© informaci√≥n sobre calidad en la Ley 100 de 1993. Los art√≠culos verificados que tratan este tema incluyen: {', '.join(validated_articles)}. Para obtener informaci√≥n espec√≠fica sobre alg√∫n art√≠culo, por favor preg√∫ntame directamente por el n√∫mero del art√≠culo."
            else:
                response_text = "Encontr√© informaci√≥n relacionada con calidad en la Ley 100 de 1993, pero para brindarte informaci√≥n precisa sobre art√≠culos espec√≠ficos, por favor preg√∫ntame por el n√∫mero exacto del art√≠culo que te interesa."
            
            return response_text, False
        
        return response_text, True

    def _validate_thematic_consistency(self, query_text, response_text):
        """Valida que la respuesta sea tem√°ticamente consistente con la consulta."""
        query_lower = query_text.lower()
        response_lower = response_text.lower()
        
        # Definir t√©rminos clave y sus sin√≥nimos
        key_terms = {
            'calidad': ['calidad', 'calidad de servicio', 'calidad de atenci√≥n', 'est√°ndares'],
            'art√≠culo': ['art√≠culo', 'art.', 'art√≠culos'],
            'ley 100': ['ley 100', 'ley 100 de 1993', 'ley cien'],
            'salud': ['salud', 'servicios de salud', 'atenci√≥n m√©dica', 'sistema de salud'],
            'acreditaci√≥n': ['acreditaci√≥n', 'acreditar', 'certificaci√≥n'],
            'auditor√≠a': ['auditor√≠a', 'auditor√≠as', 'control', 'evaluaci√≥n']
        }
        
        consistency_issues = []
        
        # Verificar consistencia tem√°tica principal
        for main_term, synonyms in key_terms.items():
            query_has_term = any(term in query_lower for term in synonyms)
            response_has_term = any(term in response_lower for term in synonyms)
            
            if query_has_term and not response_has_term:
                consistency_issues.append(f"Consulta menciona '{main_term}' pero respuesta no")
        
        # Si hay problemas de consistencia significativos, marcar como inconsistente
        if len(consistency_issues) > 1:  # M√°s de un problema tem√°tico
            logging.warning(f"Problemas de consistencia tem√°tica detectados: {consistency_issues}")
            return False, consistency_issues
        
        return True, []

    def _improve_response_coherence(self, query_text, response_text):
        """Mejora la coherencia de la respuesta bas√°ndose en la consulta."""
        
        # 1. Validar art√≠culos mencionados
        response_text, articles_valid = self._validate_article_mentions(response_text)
        
        # 2. Validar consistencia tem√°tica
        is_consistent, issues = self._validate_thematic_consistency(query_text, response_text)
        
        # 3. Si hay problemas de consistencia, generar una respuesta m√°s conservadora
        if not is_consistent or not articles_valid:
            logging.info("Generando respuesta m√°s conservadora debido a problemas de consistencia")
            
            # Buscar informaci√≥n relevante de manera m√°s espec√≠fica
            top_results = vector_db.get_top_results(query_text, top_k=3)
            
            if top_results and top_results[0]['similarity'] >= 0.6:
                # Crear respuesta basada en resultados verificados
                verified_info = []
                for result in top_results:
                    data = result['data']
                    article_num = data.get('articulo', '')
                    theme = data.get('tema', '')
                    source = data.get('fuente', '')
                    
                    if article_num and theme and source:
                        verified_info.append(f"Art√≠culo {article_num} ({source}): {theme}")
                
                if verified_info:
                    response_text = f"Bas√°ndome en mi base de datos verificada, encontr√© la siguiente informaci√≥n relevante:\n\n" + "\n".join(verified_info) + "\n\n¬øTe gustar√≠a obtener m√°s detalles sobre alg√∫n art√≠culo espec√≠fico?"
                else:
                    response_text = "Encontr√© informaci√≥n relacionada con tu consulta, pero para brindarte datos precisos y verificados, por favor especifica qu√© aspecto particular te interesa conocer."
        
        return response_text

    def query_rag(self, query_text: str) -> tuple:
        """Consulta el sistema RAG y devuelve la mejor respuesta disponible con informaci√≥n de similitud."""
        global conversation_history

        try:
            # Limpiar y normalizar la consulta
            query_text = self.clean_text(query_text)
            logging.info(f"Consulta normalizada: {query_text}")

            # NUEVA L√ìGICA: Detectar si se solicita un art√≠culo espec√≠fico
            import re
            article_pattern = r'(?:art√≠culo|articulo|art\.?)\s*(\d+)'
            match = re.search(article_pattern, query_text.lower())
            
            if match:
                article_number = match.group(1)
                logging.info(f"Solicitud de art√≠culo espec√≠fico detectada: {article_number}")
                return vector_db.get_article_details(article_number)

            # NUEVA L√ìGICA: Detectar si es una consulta de lista de art√≠culos
            if self.is_article_list_query(query_text):
                logging.info("Consulta de lista de art√≠culos detectada - usando formato est√°ndar")
                # Proceder con la b√∫squeda est√°ndar para mostrar lista de art√≠culos
                # No hacer nada especial, continuar con la l√≥gica normal
            else:
                logging.info("Consulta espec√≠fica detectada - generando respuesta con IA")
                # Para consultas espec√≠ficas, usar OpenAI con contexto de la base de datos
                top_results = vector_db.get_top_results(query_text, top_k=5)
                if top_results and top_results[0]['similarity'] >= 0.3:  # Umbral m√°s bajo para contexto
                    # Crear contexto con la informaci√≥n relevante encontrada
                    context_info = self._prepare_context_from_results(top_results)
                    ai_response = self.query_openai_with_context(query_text, context_info)
                    
                    # NUEVA MEJORA: Validar y mejorar coherencia de la respuesta
                    improved_response = self._improve_response_coherence(query_text, ai_response)
                    
                    return improved_response, top_results[0]['similarity'], True
                else:
                    # Si no hay informaci√≥n relevante, usar OpenAI sin contexto espec√≠fico
                    logging.info("No se encontr√≥ informaci√≥n relevante, consultando OpenAI sin contexto espec√≠fico")
                    context = self.get_context_from_history()
                    response = self.query_openai(query_text, context)
                    return response, 0.0, False

            # Buscar preguntas similares en FAISS
            response, similarity_score = vector_db.find_similar_question(query_text)
            
            # NUEVA MEJORA: Validar coherencia tambi√©n para respuestas de la base de conocimientos
            if similarity_score >= self.min_similarity_score:
                logging.info("Usando respuesta de la base de conocimiento")
                improved_response = self._improve_response_coherence(query_text, response)
                used_kb = True
                response = improved_response
            else:
                logging.info(f"Similitud baja ({similarity_score:.3f}), consultando OpenAI...")
                context = self.get_context_from_history()
                response = self.query_openai(query_text, context)
                used_kb = False

            # Actualizar historial
            conversation_history.append({
                "role": "user",
                "content": query_text
            })
            conversation_history.append({
                "role": "assistant",
                "content": response
            })

            # Mantener el historial manejable
            if len(conversation_history) > 10:
                conversation_history = conversation_history[-10:]

            return response, similarity_score, used_kb  # Devolver respuesta, similitud y si us√≥ KB

        except Exception as e:
            logging.error(f"Error en query_rag: {str(e)}")
            logging.error(f"Traceback completo: {traceback.format_exc()}")
            return f"Lo siento, hubo un problema al procesar tu consulta: {str(e)}", 0.0, False

    def search_by_theme(self, theme: str, subtema: str = None) -> str:
        """Busca art√≠culos espec√≠ficamente por tema y subtema."""
        try:
            # Verificar si tenemos nueva estructura
            if not hasattr(vector_db, 'df') or vector_db.df is None:
                return "La base de datos no est√° disponible."
            
            has_new_structure = all(col in vector_db.df.columns for col in ['fuente', 'articulo', 'tema', 'subtema', 'texto_del_articulo', 'categorias', 'resumen_explicativo'])
            
            if not has_new_structure:
                return "Esta funcionalidad requiere la nueva estructura de base de datos."
            
            # Filtrar por tema
            theme_filter = vector_db.df['tema'].str.contains(theme, case=False, na=False)
            filtered_df = vector_db.df[theme_filter]
            
            if subtema:
                subtema_filter = filtered_df['subtema'].str.contains(subtema, case=False, na=False)
                filtered_df = filtered_df[subtema_filter]
            
            if filtered_df.empty:
                return f"No se encontraron art√≠culos para el tema '{theme}'{f' y subtema {subtema}' if subtema else ''}."
            
            # Generar respuesta estructurada
            response = f"üìã **Art√≠culos sobre {theme.upper()}:**\n\n"
            
            for idx, row in filtered_df.head(10).iterrows():  # Limitar a 10 resultados
                article_num = row['articulo']
                source = row['fuente']
                summary = row['resumen_explicativo']
                subtema_info = row['subtema']
                
                response += f"‚Ä¢ **Art. {article_num}** ({source})"
                if subtema_info and subtema_info.strip():
                    response += f" - *{subtema_info}*"
                response += f"\n  {summary}\n\n"
            
            if len(filtered_df) > 10:
                response += f"... y {len(filtered_df) - 10} art√≠culo{'s' if len(filtered_df) - 10 > 1 else ''} m√°s.\n\n"
            
            response += "¬øNecesitas informaci√≥n m√°s detallada de alg√∫n art√≠culo espec√≠fico?"
            
            return response
            
        except Exception as e:
            logging.error(f"Error en search_by_theme: {str(e)}")
            return f"Error al buscar por tema: {str(e)}"
    
    def get_article_details(self, article_number: str) -> str:
        """Obtiene los detalles completos de un art√≠culo espec√≠fico."""
        try:
            if not hasattr(vector_db, 'df') or vector_db.df is None:
                return "‚ùå **Error de Base de Datos**\n\nLa base de datos no est√° disponible en este momento. Por favor, intenta m√°s tarde."
            
            has_new_structure = all(col in vector_db.df.columns for col in ['fuente', 'articulo', 'tema', 'subtema', 'texto_del_articulo', 'categorias', 'resumen_explicativo'])
            
            if not has_new_structure:
                return "‚ùå **Funcionalidad No Disponible**\n\nEsta funcionalidad requiere la nueva estructura de base de datos que a√∫n no est√° implementada."
            
            # Buscar el art√≠culo
            article_filter = vector_db.df['articulo'].astype(str).str.contains(str(article_number), case=False, na=False)
            article_df = vector_db.df[article_filter]
            
            if article_df.empty:
                return f"‚ùå **Art√≠culo No Encontrado**\n\nNo se encontr√≥ el art√≠culo {article_number} en mi base de datos.\n\n**Posibles razones:**\n‚Ä¢ El art√≠culo no existe en la Ley 100 de 1993\n‚Ä¢ El n√∫mero de art√≠culo es incorrecto\n‚Ä¢ El art√≠culo no est√° incluido en mi base de datos actual\n\nüí° **Sugerencia:** Verifica el n√∫mero del art√≠culo o consulta la lista completa de art√≠culos disponibles."
            
            # Tomar el primer resultado si hay m√∫ltiples
            article = article_df.iloc[0]
            
            # Verificar si el art√≠culo tiene contenido v√°lido
            if not article['texto_del_articulo'] or str(article['texto_del_articulo']).strip() in ['', 'nan', 'None']:
                return f"‚ö†Ô∏è **Informaci√≥n Limitada - Art√≠culo {article['articulo']}**\n\n**Fuente:** {article['fuente']}\n**Tema:** {article['tema']}\n\n‚ùå **Texto Completo No Disponible**\n\nLamentablemente, el texto completo de este art√≠culo no est√° disponible en mi base de datos actual.\n\n**Lo que s√≠ puedo ofrecerte:**\n‚Ä¢ Informaci√≥n tem√°tica general\n‚Ä¢ Resumen explicativo (si est√° disponible)\n‚Ä¢ Orientaci√≥n sobre el tema que trata\n\nüí° **Para obtener el texto completo:** Te recomiendo consultar directamente la Ley 100 de 1993 en fuentes oficiales como el Diario Oficial o portales gubernamentales."
            
            response = f"üìÑ **Art√≠culo {article['articulo']}**\n\n"
            response += f"**Fuente:** {article['fuente']}\n"
            response += f"**Tema:** {article['tema']}\n"
            if article['subtema'] and str(article['subtema']).strip() not in ['', 'nan', 'None']:
                response += f"**Subtema:** {article['subtema']}\n"
            if article['categorias'] and str(article['categorias']).strip() not in ['', 'nan', 'None']:
                response += f"**Categor√≠as:** {article['categorias']}\n"
            response += f"\n**Contenido:**\n{article['texto_del_articulo']}\n\n"
            
            if article['resumen_explicativo'] and str(article['resumen_explicativo']).strip() not in ['', 'nan', 'None']:
                response += f"**Resumen:** {article['resumen_explicativo']}"
            
            return response
            
        except Exception as e:
            logging.error(f"Error en get_article_details: {str(e)}")
            return f"‚ùå **Error T√©cnico**\n\nOcurri√≥ un error al obtener los detalles del art√≠culo: {str(e)}\n\nPor favor, intenta nuevamente o contacta al administrador del sistema."

    def get_context_from_history(self) -> str:
        """Obtiene contexto relevante del historial de conversaci√≥n."""
        if not conversation_history:
            return ""
        
        # Tomar las √∫ltimas 3 interacciones
        recent_history = conversation_history[-6:]
        context = "\n".join([f"{'Usuario' if msg['role'] == 'user' else 'Asistente'}: {msg['content']}" 
                           for msg in recent_history])
        return context

    def _prepare_context_from_results(self, results):
        """Prepara el contexto basado en los resultados de la b√∫squeda."""
        context_parts = []
        context_parts.append("INFORMACI√ìN RELEVANTE DE LA BASE DE DATOS:")
        
        for i, result in enumerate(results[:3]):  # Usar solo los 3 m√°s relevantes
            data = result['data']
            similarity = result['similarity']
            
            context_parts.append(f"\n--- Resultado {i+1} (Similitud: {similarity:.3f}) ---")
            context_parts.append(f"Art√≠culo: {data.get('articulo', 'N/A')}")
            context_parts.append(f"Fuente: {data.get('fuente', 'N/A')}")
            context_parts.append(f"Tema: {data.get('tema', 'N/A')}")
            context_parts.append(f"Subtema: {data.get('subtema', 'N/A')}")
            
            # Incluir resumen si est√° disponible
            if data.get('resumen_explicativo') and str(data.get('resumen_explicativo')).strip() not in ['', 'nan', 'None', 'null']:
                context_parts.append(f"Resumen: {data.get('resumen_explicativo')}")
            
            # Incluir texto del art√≠culo si est√° disponible
            if data.get('texto_del_articulo') and str(data.get('texto_del_articulo')).strip() not in ['', 'nan', 'None', 'null']:
                text = data.get('texto_del_articulo')
                # Limitar el texto para no sobrecargar el contexto
                if len(text) > 500:
                    text = text[:500] + "..."
                context_parts.append(f"Texto del art√≠culo: {text}")
        
        return "\n".join(context_parts)

    def query_openai_with_context(self, query_text: str, context_info: str) -> str:
        """Consulta OpenAI con contexto espec√≠fico de la base de datos."""
        try:
            logging.info("Iniciando consulta a OpenAI con contexto espec√≠fico")
            
            # Verificar que la API key est√© configurada
            if not Config.OPENAI_API_KEY or Config.OPENAI_API_KEY == "KEY_NO_DEFINIDA":
                logging.error("API Key de OpenAI no configurada")
                return "Lo siento, no puedo procesar tu consulta en este momento. La configuraci√≥n de OpenAI no est√° disponible."
            
            import openai
            openai.api_key = Config.OPENAI_API_KEY
            
            system_prompt = """Eres AzuSENA, asistente virtual del SENA de Colombia.

INSTRUCCIONES CR√çTICAS:
1. Responde de manera natural y conversacional, como si fueras un experto humano
2. NO menciones que eres una IA o que est√°s consultando una base de datos
3. NO uses formatos de lista con vi√±etas o estructuras r√≠gidas
4. Redacta respuestas fluidas y naturales basadas en la informaci√≥n proporcionada
5. Si la informaci√≥n no es suficiente para responder completamente, di que necesitas m√°s detalles espec√≠ficos

FORMATO DE RESPUESTA:
- Respuesta directa y natural
- Explicaci√≥n clara del procedimiento o informaci√≥n solicitada
- Menciona las referencias legales de forma natural en el texto
- Termina preguntando si necesita m√°s informaci√≥n espec√≠fica

PROHIBIDO:
- Usar listas con vi√±etas (‚Ä¢)
- Usar formatos estructurados r√≠gidos
- Mencionar "base de datos" o "sistema"
- Decir "seg√∫n mi base de datos"
- Usar emojis excesivos"""

            user_prompt = f"""Pregunta del usuario: {query_text}

{context_info}

Responde de manera natural y conversacional bas√°ndote en la informaci√≥n proporcionada. Si la informaci√≥n es relevante, √∫sala para dar una respuesta completa. Si no es suficiente, explica qu√© informaci√≥n adicional necesitar√≠as."""

            # Configurar cliente OpenAI
            client = OpenAI(api_key=Config.OPENAI_API_KEY)
            
            if not Config.OPENAI_API_KEY or Config.OPENAI_API_KEY == "KEY_NO_DEFINIDA":
                logging.error("API Key de OpenAI no configurada")
                return "Lo siento, el servicio de consulta no est√° disponible en este momento."

            response = client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                max_tokens=800,
                temperature=0.7
            )
            
            ai_response = response.choices[0].message.content.strip()
            logging.info("Respuesta de OpenAI generada exitosamente")
            return ai_response
            
        except Exception as e:
            logging.error(f"Error consultando OpenAI con contexto: {str(e)}")
            return f"Lo siento, no pude procesar tu consulta en este momento. Por favor, intenta reformular tu pregunta o consulta m√°s tarde."

    def query_openai(self, query_text: str, context: str = "") -> str:
        """Consulta OpenAI para respuestas generales sin contexto espec√≠fico."""
        try:
            logging.info("Iniciando consulta a OpenAI sin contexto espec√≠fico")
            
            # Verificar que la API key est√© configurada
            if not Config.OPENAI_API_KEY:
                logging.error("API Key de OpenAI no configurada")
                return "Lo siento, no puedo procesar tu consulta en este momento. La configuraci√≥n de OpenAI no est√° disponible."
            
            # Configurar cliente OpenAI
            client = OpenAI(api_key=Config.OPENAI_API_KEY)
            
            system_prompt = """Eres AzuSENA, asistente virtual del SENA de Colombia.

INSTRUCCIONES CR√çTICAS:
1. Responde de manera natural y conversacional
2. Proporciona informaci√≥n general sobre procedimientos administrativos colombianos
3. Si no tienes informaci√≥n espec√≠fica, s√© honesto al respecto
4. Sugiere consultar fuentes oficiales cuando sea apropiado
5. Mant√©n un tono profesional pero amigable

FORMATO DE RESPUESTA:
- Respuesta directa y natural
- Informaci√≥n general disponible
- Sugerencias de fuentes oficiales si es necesario
- Pregunta si necesita m√°s ayuda espec√≠fica

PROHIBIDO:
- Inventar informaci√≥n espec√≠fica de leyes o art√≠culos
- Dar informaci√≥n incorrecta
- Usar formatos excesivamente estructurados"""

            user_prompt = f"""Pregunta del usuario: {query_text}

{context if context else ""}

Responde de manera natural proporcionando la informaci√≥n general que tengas disponible. Si no tienes informaci√≥n espec√≠fica, sugiere fuentes oficiales apropiadas."""

            response = client.chat.completions.create(
                 model="gpt-3.5-turbo",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                max_tokens=600,
                temperature=0.7
            )
            
            ai_response = response.choices[0].message.content.strip()
            logging.info("Respuesta de OpenAI generada exitosamente")
            return ai_response
            
        except Exception as e:
            logging.error(f"Error consultando OpenAI: {str(e)}")
            return f"Lo siento, no pude procesar tu consulta en este momento. Por favor, intenta m√°s tarde o consulta directamente con las oficinas del SENA."

    def query_openai_with_context_full(self, query_text: str, context: str = "") -> str:
        """Consulta OpenAI con contexto mejorado."""
        try:
            logging.info("Iniciando consulta a OpenAI")
            logging.info(f"API Key actual: {Config.OPENAI_API_KEY[:10]}...")

            system_prompt = """Nombre: AzuSENA
Rol: Asistente virtual del Servicio Nacional de Aprendizaje (SENA) de Colombia.
Funci√≥n Principal: Proporcionar respuestas precisas y confiables sobre temas administrativos, jur√≠dicos, y acad√©micos del SENA (y en general del contexto jur√≠dico, legal y normativo colombiano) a aprendices, instructores, y funcionarios del SENA (Servicio nacional de aprendizaje), instituci√≥n educativa t√©cnica y tecnol√≥gica colombiana, y sabe que el √©nfasis de los temas administrativos que requiere el SENA esta en el contexto colombiano, por lo que entiende que las preguntas administrativas que le hacen los usuarios son referidas al contexto colombiano, o sea que el usuario es colombiano, y por eso al pedirle una pregunta jur√≠dica o administrativa, espera respuestas en base al contexto jur√≠dico colombiano, por ejemplo si piden algo sobre leyes o normativas sobre salud o educaci√≥n, sabe se necesita responder en base a leyes o normativas colombianas, por eso busca responder en base a leyes, normas, decretos o documentos jur√≠dico de Colombia, que se aplique en Colombia y que regulen esos aspectos en Colombia, excepto si el usuario aclara que necesita alg√∫n dato jur√≠dico de un contexto jur√≠dico de otro pa√≠s que no sea Colombia.

Directrices de Comportamiento:
1. Identidad: Siempre pres√©ntate como AzuSENA, asistente virtual del SENA (la instituci√≥n colombiana).

2. Fuentes de Informaci√≥n: 
   - PRIORIDAD ABSOLUTA: Utiliza √öNICAMENTE la informaci√≥n de tu base de datos RAG cuando se trate de art√≠culos espec√≠ficos, leyes, decretos o normativas.
   - PROHIBIDO TERMINANTEMENTE: NO inventes, no crees, no generes art√≠culos, n√∫meros de art√≠culos, o contenido espec√≠fico de leyes que no est√© en tu base de datos.
   
   **REGLAS CR√çTICAS PARA MOSTRAR TEXTO COMPLETO:**
   - Si la funci√≥n get_article_details() devuelve un art√≠culo CON contenido en la secci√≥n "**Contenido:**", entonces TIENES el texto completo y DEBES mostrarlo completamente.
   - NUNCA digas que "no tienes el texto completo disponible" si la funci√≥n get_article_details() ya te proporcion√≥ el contenido del art√≠culo.
   - Solo di que "no tienes el texto completo" si la funci√≥n get_article_details() devuelve "‚ùå **Texto Completo No Disponible**".
   
   - CUANDO S√ç TIENES LA INFORMACI√ìN: Si encuentras un art√≠culo en tu base de datos Y la funci√≥n te devuelve el contenido, DEBES proporcionarlo completamente. No seas evasivo.
   - CUANDO NO TIENES LA INFORMACI√ìN: Si no encuentras informaci√≥n espec√≠fica en tu base de datos RAG, debes ser COMPLETAMENTE TRANSPARENTE y decir: "No encontr√© informaci√≥n espec√≠fica sobre [tema] en mi base de datos."

3. Precisi√≥n y Confiabilidad CR√çTICA:
   - NUNCA inventes n√∫meros de art√≠culos, contenido de leyes, o informaci√≥n jur√≠dica espec√≠fica.
   - Si la consulta es sobre art√≠culos espec√≠ficos de una ley y no los encuentras en tu base de datos, admite claramente esta limitaci√≥n.
   - Solo proporciona informaci√≥n general de tu conocimiento base cuando sea apropiado y SIEMPRE aclarando que no proviene de tu base de datos especializada.
   - Si un usuario solicita el texto completo de un art√≠culo y no est√° disponible, explica claramente las limitaciones de tu base de datos.

4. Transparencia Obligatoria:
   - Cuando uses informaci√≥n de tu base de datos RAG, indica: "Seg√∫n mi base de datos especializada..."
   - Cuando uses conocimiento general, indica: "Bas√°ndome en informaci√≥n general (no de mi base de datos especializada)..."
   - Cuando no tengas informaci√≥n, indica claramente: "No dispongo de informaci√≥n verificada sobre este tema espec√≠fico."
   
   **REGLA ABSOLUTA PARA TEXTO COMPLETO:**
   - Si get_article_details() te devuelve contenido en la secci√≥n "**Contenido:**", ESO ES EL TEXTO COMPLETO y debes mostrarlo.
   - NO inventes excusas sobre "texto no verificado" cuando la funci√≥n ya te proporcion√≥ el contenido.
   - El contenido de tu base de datos YA EST√Å VERIFICADO por definici√≥n.

5. Limitaciones de Base de Datos:
   - S√© transparente sobre qu√© tipo de informaci√≥n contiene tu base de datos (temas, res√∫menes, referencias) versus lo que NO contiene.
   - Sugiere fuentes oficiales SOLO cuando realmente no tengas la informaci√≥n solicitada.
   - Nunca finjas tener acceso a informaci√≥n que no posees.
   - IMPORTANTE: Si la informaci√≥n est√° en tu base de datos, proporci√≥nala directamente sin excusas.

6. Respuesta Directa y Concisa: Responde de manera detallada pero precisa, evitando informaci√≥n innecesaria.

7. Tono: Mant√©n un tono formal pero amigable, profesional, y respetuoso. S√© amable y servicial.

## üìã FORMATO DE RESPUESTA OBLIGATORIO

**SIEMPRE usa el siguiente formato HTML para estructurar tus respuestas:**

### Para Respuestas Generales:
```
# üéØ [T√≠tulo Principal de la Respuesta]

## üìñ Informaci√≥n Relevante

[Contenido principal aqu√≠]

### üìå Puntos Clave:
- **Punto 1:** Descripci√≥n
- **Punto 2:** Descripci√≥n  
- **Punto 3:** Descripci√≥n

---

üí° **Nota importante:** [Si aplica]

¬øPuedo ayudarte con algo m√°s?
```

### Para Listados de Art√≠culos/Normativas:
```
# üìö [T√≠tulo de la Consulta]

Seg√∫n mi base de datos especializada, encontr√© informaci√≥n sobre '[tema]' en los siguientes art√≠culos:

## üìÑ Art√≠culos Encontrados

### üîπ **ART√çCULO [N√öMERO ESPEC√çFICO]** - [NOMBRE DE LA LEY/NORMA]
**Tema:** [Tema espec√≠fico]
**Subtema:** [Subtema espec√≠fico]
**Contenido:** [Descripci√≥n del contenido del art√≠culo]

### üîπ **ART√çCULO [N√öMERO ESPEC√çFICO]** - [NOMBRE DE LA LEY/NORMA]  
**Tema:** [Tema espec√≠fico]
**Subtema:** [Subtema espec√≠fico]
**Contenido:** [Descripci√≥n del contenido del art√≠culo]

### üîπ **ART√çCULO [N√öMERO ESPEC√çFICO]** - [NOMBRE DE LA LEY/NORMA]
**Tema:** [Tema espec√≠fico] 
**Subtema:** [Subtema espec√≠fico]
**Contenido:** [Descripci√≥n del contenido del art√≠culo]

---

üí° **¬øNecesitas m√°s detalles?** Puedo profundizar en cualquiera de estos art√≠culos.

¬øHay algo m√°s en lo que pueda ayudarte?
```

### Para Informaci√≥n T√©cnica/Procedimental:
```
# ‚öôÔ∏è [T√≠tulo del Procedimiento]

## üìã Pasos a Seguir

### üîπ Paso 1: [Nombre del paso]
[Descripci√≥n detallada]

### üîπ Paso 2: [Nombre del paso]
[Descripci√≥n detallada]

## üìå Requisitos Importantes
- ‚úÖ **Requisito 1:** Descripci√≥n
- ‚úÖ **Requisito 2:** Descripci√≥n

## ‚ö†Ô∏è Consideraciones Especiales
[Si aplica]

---

¬øTe gustar√≠a que profundice en alg√∫n paso espec√≠fico?
```

6. Estructura de la Respuesta:
   ‚Ä¢ SIEMPRE usa los formatos Markdown especificados arriba
   ‚Ä¢ Incluye emojis apropiados para mejorar la legibilidad
   ‚Ä¢ Usa negritas (**texto**) para resaltar informaci√≥n importante
   ‚Ä¢ Separa secciones con l√≠neas (---) cuando sea apropiado
   ‚Ä¢ Usa #, ##, ### para t√≠tulos jer√°rquicos
   ‚Ä¢ Usa p√°rrafos normales y listas con guiones (-)
   ‚Ä¢ Termina siempre con una pregunta amigable para continuar la conversaci√≥n

Restricciones CR√çTICAS:
‚Ä¢ PROHIBICI√ìN ABSOLUTA: NO inventes, no crees, no generes informaci√≥n sobre art√≠culos espec√≠ficos, n√∫meros de art√≠culos, contenido de leyes, decretos o normativas que no est√©n en tu base de datos RAG.
‚Ä¢ TRANSPARENCIA OBLIGATORIA: Si no encuentras informaci√≥n espec√≠fica en tu base de datos, admite claramente esta limitaci√≥n con frases como: "No encontr√© informaci√≥n espec√≠fica sobre [tema] en mi base de datos especializada" o "No dispongo de art√≠culos verificados sobre este tema espec√≠fico."
‚Ä¢ VERIFICACI√ìN REQUERIDA: Solo proporciona n√∫meros de art√≠culos, contenido jur√≠dico espec√≠fico, o referencias normativas que est√©n CONFIRMADOS en tu base de datos RAG.
‚Ä¢ N√öMEROS DE ART√çCULOS OBLIGATORIOS: Cuando encuentres art√≠culos en tu base de datos RAG, SIEMPRE debes mostrar el n√∫mero espec√≠fico del art√≠culo (ej: "ART√çCULO 227", "ART√çCULO 231") junto con el nombre completo de la ley o norma.
‚Ä¢ FORMATO ESPEC√çFICO REQUERIDO: Para cada art√≠culo encontrado, usa el formato: "**ART√çCULO [N√öMERO EXACTO]** - [NOMBRE COMPLETO DE LA LEY]"
‚Ä¢ HONESTIDAD PROFESIONAL: Es mejor admitir limitaciones que proporcionar informaci√≥n potencialmente incorrecta o inventada.
‚Ä¢ No proporciones opiniones personales, juicios de valor o informaci√≥n no verificable.
‚Ä¢ Si te piden informaci√≥n que implique alg√∫n juicio de valor, informa que eres neutral y que tu labor es proporcionar informaci√≥n confiable y verificada.
‚Ä¢ Puedes mencionar tu modelo base, pero siempre enfatiza que para informaci√≥n jur√≠dica espec√≠fica dependes de tu base de datos RAG especializada."""

            messages = [
                {"role": "system", "content": system_prompt}
            ]

            if context:
                messages.append({
                    "role": "system",
                    "content": f"Contexto de la conversaci√≥n previa:\n{context}"
                })

            messages.append({"role": "user", "content": query_text})

            logging.info("Enviando solicitud a OpenAI...")
            response = self.client.chat.completions.create(
                model=Config.OPENAI_MODEL,
                messages=messages,
                temperature=0.7,
                max_tokens=500
            )
            logging.info("Respuesta recibida de OpenAI")

            return response.choices[0].message.content

        except Exception as e:
            logging.error(f"Error consultando OpenAI: {str(e)}")
            logging.error(f"Traceback completo: {traceback.format_exc()}")
            raise Exception(f"Error al consultar OpenAI: {str(e)}")

# Instancia global
query_rag_system = QueryRAGSystem()
